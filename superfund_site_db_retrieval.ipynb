{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_abbrev = {'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR',\n",
    "    'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC', 'Florida': 'FL', 'Georgia': 'GA', 'Guam': 'GU', \n",
    "    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n",
    "    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME',\n",
    "    'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
    "    'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA', 'Puerto Rico': 'PR', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT',\n",
    "    'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list of \n",
    "states = list(state_abbrev.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL added to DataFrame\n",
      "AK added to DataFrame\n",
      "AZ added to DataFrame\n",
      "AR added to DataFrame\n",
      "CA added to DataFrame\n",
      "CO added to DataFrame\n",
      "CT added to DataFrame\n",
      "DE added to DataFrame\n",
      "DC added to DataFrame\n",
      "FL added to DataFrame\n",
      "GA added to DataFrame\n",
      "GU added to DataFrame\n",
      "HI added to DataFrame\n",
      "ID added to DataFrame\n",
      "IL added to DataFrame\n",
      "IN added to DataFrame\n",
      "IA added to DataFrame\n",
      "KS added to DataFrame\n",
      "KY added to DataFrame\n",
      "LA added to DataFrame\n",
      "ME added to DataFrame\n",
      "MD added to DataFrame\n",
      "MA added to DataFrame\n",
      "MI added to DataFrame\n",
      "MN added to DataFrame\n",
      "MS added to DataFrame\n",
      "MO added to DataFrame\n",
      "MT added to DataFrame\n",
      "NE added to DataFrame\n",
      "NV added to DataFrame\n",
      "NH added to DataFrame\n",
      "NJ added to DataFrame\n",
      "NM added to DataFrame\n",
      "NY added to DataFrame\n",
      "NC added to DataFrame\n",
      "ND added to DataFrame\n",
      "OH added to DataFrame\n",
      "OK added to DataFrame\n",
      "OR added to DataFrame\n",
      "PA added to DataFrame\n",
      "PR added to DataFrame\n",
      "RI added to DataFrame\n",
      "SC added to DataFrame\n",
      "SD added to DataFrame\n",
      "TN added to DataFrame\n",
      "TX added to DataFrame\n",
      "UT added to DataFrame\n",
      "VT added to DataFrame\n",
      "VA added to DataFrame\n",
      "WA added to DataFrame\n",
      "WV added to DataFrame\n",
      "WI added to DataFrame\n",
      "WY added to DataFrame\n",
      "----------------------\n",
      "Data download complete \n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# API request for each ACTIVE site by State ID, then append into one DataFrame. \n",
    "# Notes:\n",
    "# 1) multiple attempts were made to request the data in one lump without a loop; however, they either did not \n",
    "# return any data, or were prohibitively slow\n",
    "# 2) EPA includes a large amount of inactive site in the Active table in their DataBase\n",
    "x = 0\n",
    "for state in states:\n",
    "    try:\n",
    "        request = requests.get(f'https://data.epa.gov/efservice/SEMS_ACTIVE_SITES/SITE_STATE/CONTAINING/{state}/JSON').json()\n",
    "        temp_df = pd.DataFrame(request)\n",
    "        if x == 0:\n",
    "            sf_active_df = temp_df.copy()\n",
    "            print(f'{state} added to DataFrame')\n",
    "            x = 1\n",
    "        else:\n",
    "            sf_active_df = pd.concat([sf_active_df, temp_df])\n",
    "            print(f'{state} added to DataFrame')\n",
    "    except Exception:\n",
    "        print(Exception)\n",
    "        print(f'Exception occurred on {state}')\n",
    "print('----------------------\\n\\\n",
    "Data download complete \\n\\\n",
    "----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves as .csv file\n",
    "sf_active_df.to_csv('resources/superfund_sites.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
